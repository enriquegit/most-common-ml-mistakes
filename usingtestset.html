<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Mistake 6: Using the test set for fine tunning | MOST COMMON MISTAKES IN MACHINE LEARNING AND HOW TO AVOID THEM</title>
  <meta name="description" content="This is a compilation of the most common mistakes in machine learning and how to avoid them. The book includes examples in the Python programming language. After reading this book, you will be ready to build more robust and trustworthy machine learning models." />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="Mistake 6: Using the test set for fine tunning | MOST COMMON MISTAKES IN MACHINE LEARNING AND HOW TO AVOID THEM" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/images/cover.jpg" />
  <meta property="og:description" content="This is a compilation of the most common mistakes in machine learning and how to avoid them. The book includes examples in the Python programming language. After reading this book, you will be ready to build more robust and trustworthy machine learning models." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Mistake 6: Using the test set for fine tunning | MOST COMMON MISTAKES IN MACHINE LEARNING AND HOW TO AVOID THEM" />
  
  <meta name="twitter:description" content="This is a compilation of the most common mistakes in machine learning and how to avoid them. The book includes examples in the Python programming language. After reading this book, you will be ready to build more robust and trustworthy machine learning models." />
  <meta name="twitter:image" content="/images/cover.jpg" />

<meta name="author" content="Enrique Garcia Ceja" />


<meta name="date" content="2025-09-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ignoringscales.html"/>
<link rel="next" href="onlyaccuracy.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-X0JKZ260BD"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-X0JKZ260BD');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="#">MOST COMMON MISTAKES IN MACHINE LEARNING AND HOW TO AVOID THEM</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i>About the Author</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="dedication.html"><a href="dedication.html"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="" data-path="protecting-the-neural-tree.html"><a href="protecting-the-neural-tree.html"><i class="fa fa-check"></i>Protecting the Neural Tree</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#supplemental-material"><i class="fa fa-check"></i>Supplemental Material</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#conventions"><i class="fa fa-check"></i>Conventions</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#terminology"><i class="fa fa-check"></i>Terminology</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="notunderstandingdata.html"><a href="notunderstandingdata.html"><i class="fa fa-check"></i><b>1</b> Not understanding the data</a></li>
<li class="chapter" data-level="2" data-path="trainperformance.html"><a href="trainperformance.html"><i class="fa fa-check"></i><b>2</b> Reporting train performance</a></li>
<li class="chapter" data-level="3" data-path="settingseed.html"><a href="settingseed.html"><i class="fa fa-check"></i><b>3</b> Not setting a seed value</a></li>
<li class="chapter" data-level="4" data-path="irrelevantfeatures.html"><a href="irrelevantfeatures.html"><i class="fa fa-check"></i><b>4</b> Including irrelevant features</a></li>
<li class="chapter" data-level="5" data-path="ignoringscales.html"><a href="ignoringscales.html"><i class="fa fa-check"></i><b>5</b> Ignoring differences in scales</a></li>
<li class="chapter" data-level="6" data-path="usingtestset.html"><a href="usingtestset.html"><i class="fa fa-check"></i><b>6</b> Using the test set for fine tunning</a></li>
<li class="chapter" data-level="7" data-path="onlyaccuracy.html"><a href="onlyaccuracy.html"><i class="fa fa-check"></i><b>7</b> Only reporting accuracy</a></li>
<li class="chapter" data-level="8" data-path="notbaseline.html"><a href="notbaseline.html"><i class="fa fa-check"></i><b>8</b> Not comparing against a baseline</a></li>
<li class="chapter" data-level="9" data-path="accountingvariance.html"><a href="accountingvariance.html"><i class="fa fa-check"></i><b>9</b> Not accounting for variance</a></li>
<li class="chapter" data-level="10" data-path="datainjection.html"><a href="datainjection.html"><i class="fa fa-check"></i><b>10</b> Injecting data into the test set</a></li>
<li class="chapter" data-level="11" data-path="notshuffling.html"><a href="notshuffling.html"><i class="fa fa-check"></i><b>11</b> Not shuffling the training data</a></li>
<li class="chapter" data-level="12" data-path="savingresults.html"><a href="savingresults.html"><i class="fa fa-check"></i><b>12</b> Not saving the results</a></li>
<li class="chapter" data-level="13" data-path="notparallelizing.html"><a href="notparallelizing.html"><i class="fa fa-check"></i><b>13</b> Not parallelizing</a></li>
<li class="chapter" data-level="14" data-path="encodingintegers.html"><a href="encodingintegers.html"><i class="fa fa-check"></i><b>14</b> Encoding categories as integers</a></li>
<li class="chapter" data-level="15" data-path="datachanges.html"><a href="datachanges.html"><i class="fa fa-check"></i><b>15</b> Forgetting that data changes over time</a></li>
<li class="chapter" data-level="16" data-path="interuservariance.html"><a href="interuservariance.html"><i class="fa fa-check"></i><b>16</b> Ignoring inter-user variance</a></li>
<li class="chapter" data-level="17" data-path="wastingunlabeled.html"><a href="wastingunlabeled.html"><i class="fa fa-check"></i><b>17</b> Wasting unlabeled data</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendixInstall.html"><a href="appendixInstall.html"><i class="fa fa-check"></i><b>A</b> Setup Your Environment</a></li>
<li class="chapter" data-level="B" data-path="appendixDatasets.html"><a href="appendixDatasets.html"><i class="fa fa-check"></i><b>B</b> Datasets</a>
<ul>
<li class="chapter" data-level="B.1" data-path="appendixDatasets.html"><a href="appendixDatasets.html#california-housing"><i class="fa fa-check"></i><b>B.1</b> CALIFORNIA-HOUSING</a></li>
<li class="chapter" data-level="B.2" data-path="appendixDatasets.html"><a href="appendixDatasets.html#diagnostic"><i class="fa fa-check"></i><b>B.2</b> DIAGNOSTIC</a></li>
<li class="chapter" data-level="B.3" data-path="appendixDatasets.html"><a href="appendixDatasets.html#digits"><i class="fa fa-check"></i><b>B.3</b> DIGITS</a></li>
<li class="chapter" data-level="B.4" data-path="appendixDatasets.html"><a href="appendixDatasets.html#income"><i class="fa fa-check"></i><b>B.4</b> INCOME</a></li>
<li class="chapter" data-level="B.5" data-path="appendixDatasets.html"><a href="appendixDatasets.html#iris"><i class="fa fa-check"></i><b>B.5</b> IRIS</a></li>
<li class="chapter" data-level="B.6" data-path="appendixDatasets.html"><a href="appendixDatasets.html#wine"><i class="fa fa-check"></i><b>B.6</b> WINE</a></li>
<li class="chapter" data-level="B.7" data-path="appendixDatasets.html"><a href="appendixDatasets.html#wisdm"><i class="fa fa-check"></i><b>B.7</b> WISDM</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="citing-this-book.html"><a href="citing-this-book.html"><i class="fa fa-check"></i>Citing this Book</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MOST COMMON MISTAKES IN MACHINE LEARNING AND HOW TO AVOID THEM</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="usingtestset" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Mistake 6:</span> Using the test set for fine tunning<a href="usingtestset.html#usingtestset" class="anchor-section" aria-label="Anchor link to header"></a></h1>

<div class="rmdmistake">
Using the test set for fine tunning your models and/or preprocessing methods.
</div>
<p></br></p>
<p>Most machine learning models require some hyper-parameter tuning. For example, KNN requires to specify the number of nearest neighbors <span class="math inline">\(k\)</span> and the distance function (Euclidean, Manhattan, etc.). In decision trees, you need to specify the feature importance function, maximum tree depth, etc. For ensembles, you need to specify the number of models, and so on. Parameter tuning can also occur when preprocessing the data. For example, when applying a moving average filter to timeseries data, one needs to define the window size.</p>
<p>Finding the best hyper-parameters requires trying different values either by hand, or by using optimization procedures such as grid search, genetic algorithms, Bayesian optimization, to name a few.</p>
<p>One of the most common mistakes occurs when using the test set to optimize hyper-parameters. Figure <a href="usingtestset.html#fig:params-test">6.1</a> exemplifies this scenario. Here, the best <span class="math inline">\(k\)</span> for KNN is looked for. The model was fitted using a train set. Then, different values of <span class="math inline">\(k\)</span> (1-3) are evaluated using the test set. In this case, the model is being overfitted to the test set.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:params-test"></span>
<img src="images/hyper-parameters-test.png" alt="Overfitting a model to the test set." width="50%" />
<p class="caption">
Figure 6.1: Overfitting a model to the test set.
</p>
</div>
<p>The following code snippet illustrates this same scenario when building a KNN classifier for the <em>WISDM</em> dataset.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode numberSource python numberLines"><code class="sourceCode python"><span id="cb17-1"><a href="usingtestset.html#cb17-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X_scaled, y,</span>
<span id="cb17-2"><a href="usingtestset.html#cb17-2"></a>                                                    test_size <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span id="cb17-3"><a href="usingtestset.html#cb17-3"></a>                                                    random_state <span class="op">=</span> <span class="dv">123</span>)</span>
<span id="cb17-4"><a href="usingtestset.html#cb17-4"></a>scaler <span class="op">=</span> MinMaxScaler()</span>
<span id="cb17-5"><a href="usingtestset.html#cb17-5"></a>X_train_scaled <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb17-6"><a href="usingtestset.html#cb17-6"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb17-7"><a href="usingtestset.html#cb17-7"></a></span>
<span id="cb17-8"><a href="usingtestset.html#cb17-8"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb17-9"><a href="usingtestset.html#cb17-9"></a>    knn <span class="op">=</span> KNeighborsClassifier(n_neighbors <span class="op">=</span> i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb17-10"><a href="usingtestset.html#cb17-10"></a>    knn.fit(X_train_scaled, y_train)</span>
<span id="cb17-11"><a href="usingtestset.html#cb17-11"></a>    y_pred <span class="op">=</span> knn.predict(X_test_scaled)</span>
<span id="cb17-12"><a href="usingtestset.html#cb17-12"></a>    accuracy <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb17-13"><a href="usingtestset.html#cb17-13"></a>    <span class="bu">print</span>(<span class="ss">f&quot;k=</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">&quot;</span> <span class="ss">f&quot; accuracy </span><span class="sc">{</span>accuracy<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb18"><pre class="sourceCode python python-output"><code class="sourceCode python"><span id="cb18-1"><a href="usingtestset.html#cb18-1" tabindex="-1"></a><span class="co">#&gt;&gt; k=1 accuracy 0.83</span></span>
<span id="cb18-2"><a href="usingtestset.html#cb18-2" tabindex="-1"></a><span class="co">#&gt;&gt; k=2 accuracy 0.79</span></span>
<span id="cb18-3"><a href="usingtestset.html#cb18-3" tabindex="-1"></a><span class="co">#&gt;&gt; k=3 accuracy 0.81</span></span>
<span id="cb18-4"><a href="usingtestset.html#cb18-4" tabindex="-1"></a><span class="co">#&gt;&gt; k=4 accuracy 0.80</span></span>
<span id="cb18-5"><a href="usingtestset.html#cb18-5" tabindex="-1"></a><span class="co">#&gt;&gt; k=5 accuracy 0.80</span></span></code></pre></div>
<p>The problem with this approach is that the value of <span class="math inline">\(k\)</span> is being chosen specifically for <em>this</em> test set. Thus, the modelâ€™s performance is likely being overestimated when reporting the accuracy with the best selected <span class="math inline">\(k\)</span>.</p>
<p>The correct way of evaluating different hyper-parameters is to do so using an independent set of data. Typically, this one is called the <em>validation set</em>. Instead of dividing the data into two subsets, it should be split into three subsets: <em>train</em>, <em>validation</em>, and <em>test</em> sets.</p>
<p>The model is trained with the <em>train set</em>. Then, hyper-parameter optimization is performed using the <em>validation set</em>. Once the best hyper-parameters have been found (<span class="math inline">\(k\)</span> in this example), the final model is tested only once using the <em>test set</em> (and these are the performace measures to be reported). Figure <a href="usingtestset.html#fig:params-val">6.2</a> shows this procedure.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:params-val"></span>
<img src="images/hyper-parameters-val.png" alt="Finding the best hyper-parameters using an independent validation set." width="100%" />
<p class="caption">
Figure 6.2: Finding the best hyper-parameters using an independent validation set.
</p>
</div>
<p>In code, this would look like this:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode numberSource python numberLines"><code class="sourceCode python"><span id="cb19-1"><a href="usingtestset.html#cb19-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y,</span>
<span id="cb19-2"><a href="usingtestset.html#cb19-2"></a>                                                    test_size <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span id="cb19-3"><a href="usingtestset.html#cb19-3"></a>                                                    random_state <span class="op">=</span> <span class="dv">123</span>)</span>
<span id="cb19-4"><a href="usingtestset.html#cb19-4"></a><span class="co"># Split the test set into two equal-size sets.</span></span>
<span id="cb19-5"><a href="usingtestset.html#cb19-5"></a>X_test, X_val, y_test, y_val <span class="op">=</span> train_test_split(X_test, y_test,</span>
<span id="cb19-6"><a href="usingtestset.html#cb19-6"></a>                                                    test_size <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span id="cb19-7"><a href="usingtestset.html#cb19-7"></a>                                                    random_state <span class="op">=</span> <span class="dv">123</span>)</span>
<span id="cb19-8"><a href="usingtestset.html#cb19-8"></a>scaler <span class="op">=</span> MinMaxScaler()</span>
<span id="cb19-9"><a href="usingtestset.html#cb19-9"></a>X_train_scaled <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb19-10"><a href="usingtestset.html#cb19-10"></a>X_val_scaled <span class="op">=</span> scaler.transform(X_val)</span>
<span id="cb19-11"><a href="usingtestset.html#cb19-11"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb19-12"><a href="usingtestset.html#cb19-12"></a></span>
<span id="cb19-13"><a href="usingtestset.html#cb19-13"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb19-14"><a href="usingtestset.html#cb19-14"></a>    knn <span class="op">=</span> KNeighborsClassifier(n_neighbors <span class="op">=</span> i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb19-15"><a href="usingtestset.html#cb19-15"></a>    knn.fit(X_train_scaled, y_train)</span>
<span id="cb19-16"><a href="usingtestset.html#cb19-16"></a>    y_pred <span class="op">=</span> knn.predict(X_val_scaled)</span>
<span id="cb19-17"><a href="usingtestset.html#cb19-17"></a>    accuracy <span class="op">=</span> accuracy_score(y_val, y_pred)</span>
<span id="cb19-18"><a href="usingtestset.html#cb19-18"></a>    <span class="bu">print</span>(<span class="ss">f&quot;k=</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">&quot;</span> <span class="ss">f&quot; accuracy </span><span class="sc">{</span>accuracy<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb20"><pre class="sourceCode python python-output"><code class="sourceCode python"><span id="cb20-1"><a href="usingtestset.html#cb20-1" tabindex="-1"></a><span class="co">#&gt;&gt; k=1 accuracy 0.83</span></span>
<span id="cb20-2"><a href="usingtestset.html#cb20-2" tabindex="-1"></a><span class="co">#&gt;&gt; k=2 accuracy 0.80</span></span>
<span id="cb20-3"><a href="usingtestset.html#cb20-3" tabindex="-1"></a><span class="co">#&gt;&gt; k=3 accuracy 0.81</span></span>
<span id="cb20-4"><a href="usingtestset.html#cb20-4" tabindex="-1"></a><span class="co">#&gt;&gt; k=4 accuracy 0.80</span></span>
<span id="cb20-5"><a href="usingtestset.html#cb20-5" tabindex="-1"></a><span class="co">#&gt;&gt; k=5 accuracy 0.80</span></span></code></pre></div>
<p>Here, half of the test set used as the validation set which is used to find the best <span class="math inline">\(k\)</span> (<span class="math inline">\(1\)</span> in this case).</p>
<p>Finally a KNN with <span class="math inline">\(k=1\)</span> is evaluated on the test set, and this is what is reported.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode numberSource python numberLines"><code class="sourceCode python"><span id="cb21-1"><a href="usingtestset.html#cb21-1"></a>best_k <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb21-2"><a href="usingtestset.html#cb21-2"></a>knn <span class="op">=</span> KNeighborsClassifier(n_neighbors <span class="op">=</span> best_k)</span>
<span id="cb21-3"><a href="usingtestset.html#cb21-3"></a>knn.fit(X_train_scaled, y_train)</span>
<span id="cb21-4"><a href="usingtestset.html#cb21-4"></a>y_pred <span class="op">=</span> knn.predict(X_test_scaled)</span>
<span id="cb21-5"><a href="usingtestset.html#cb21-5"></a>accuracy <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb21-6"><a href="usingtestset.html#cb21-6"></a><span class="bu">print</span>(<span class="ss">f&quot; test set accuracy </span><span class="sc">{</span>accuracy<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb22"><pre class="sourceCode python python-output"><code class="sourceCode python"><span id="cb22-1"><a href="usingtestset.html#cb22-1" tabindex="-1"></a><span class="co">#&gt;&gt; test set accuracy 0.83</span></span></code></pre></div>
</br>

<div class="rmdsolution">
When performing hyper-parameter tuning, use an independent validation set.
</div>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="ignoringscales.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="onlyaccuracy.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
