<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Mistake 16: Ignoring inter-user variance | MOST COMMON MISTAKES IN MACHINE LEARNING AND HOW TO AVOID THEM</title>
  <meta name="description" content="This is a compilation of the most common mistakes in machine learning and how to avoid them. The book includes examples in the Python programming language. After reading this book, you will be ready to build more robust and trustworthy machine learning models." />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="Mistake 16: Ignoring inter-user variance | MOST COMMON MISTAKES IN MACHINE LEARNING AND HOW TO AVOID THEM" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/images/cover.jpg" />
  <meta property="og:description" content="This is a compilation of the most common mistakes in machine learning and how to avoid them. The book includes examples in the Python programming language. After reading this book, you will be ready to build more robust and trustworthy machine learning models." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Mistake 16: Ignoring inter-user variance | MOST COMMON MISTAKES IN MACHINE LEARNING AND HOW TO AVOID THEM" />
  
  <meta name="twitter:description" content="This is a compilation of the most common mistakes in machine learning and how to avoid them. The book includes examples in the Python programming language. After reading this book, you will be ready to build more robust and trustworthy machine learning models." />
  <meta name="twitter:image" content="/images/cover.jpg" />

<meta name="author" content="Enrique Garcia Ceja" />


<meta name="date" content="2025-09-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="datachanges.html"/>
<link rel="next" href="wastingunlabeled.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-X0JKZ260BD"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-X0JKZ260BD');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="#">MOST COMMON MISTAKES IN MACHINE LEARNING AND HOW TO AVOID THEM</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i>About the Author</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="dedication.html"><a href="dedication.html"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="" data-path="protecting-the-neural-tree.html"><a href="protecting-the-neural-tree.html"><i class="fa fa-check"></i>Protecting the Neural Tree</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#supplemental-material"><i class="fa fa-check"></i>Supplemental Material</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#conventions"><i class="fa fa-check"></i>Conventions</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#terminology"><i class="fa fa-check"></i>Terminology</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="lackinginsight.html"><a href="lackinginsight.html"><i class="fa fa-check"></i><b>1</b> Lacking insight into the data</a></li>
<li class="chapter" data-level="2" data-path="trainperformance.html"><a href="trainperformance.html"><i class="fa fa-check"></i><b>2</b> Reporting train performance</a></li>
<li class="chapter" data-level="3" data-path="settingseed.html"><a href="settingseed.html"><i class="fa fa-check"></i><b>3</b> Not setting a seed value</a></li>
<li class="chapter" data-level="4" data-path="irrelevantfeatures.html"><a href="irrelevantfeatures.html"><i class="fa fa-check"></i><b>4</b> Including irrelevant features</a></li>
<li class="chapter" data-level="5" data-path="ignoringscales.html"><a href="ignoringscales.html"><i class="fa fa-check"></i><b>5</b> Ignoring differences in scales</a></li>
<li class="chapter" data-level="6" data-path="usingtestset.html"><a href="usingtestset.html"><i class="fa fa-check"></i><b>6</b> Using the test set for fine tunning</a></li>
<li class="chapter" data-level="7" data-path="onlyaccuracy.html"><a href="onlyaccuracy.html"><i class="fa fa-check"></i><b>7</b> Only reporting accuracy</a></li>
<li class="chapter" data-level="8" data-path="notbaseline.html"><a href="notbaseline.html"><i class="fa fa-check"></i><b>8</b> Not comparing against a baseline</a></li>
<li class="chapter" data-level="9" data-path="accountingvariance.html"><a href="accountingvariance.html"><i class="fa fa-check"></i><b>9</b> Not accounting for variance</a></li>
<li class="chapter" data-level="10" data-path="datainjection.html"><a href="datainjection.html"><i class="fa fa-check"></i><b>10</b> Injecting data into the test set</a></li>
<li class="chapter" data-level="11" data-path="notshuffling.html"><a href="notshuffling.html"><i class="fa fa-check"></i><b>11</b> Not shuffling the training data</a></li>
<li class="chapter" data-level="12" data-path="savingresults.html"><a href="savingresults.html"><i class="fa fa-check"></i><b>12</b> Not saving the results</a></li>
<li class="chapter" data-level="13" data-path="notparallelizing.html"><a href="notparallelizing.html"><i class="fa fa-check"></i><b>13</b> Not parallelizing</a></li>
<li class="chapter" data-level="14" data-path="encodingintegers.html"><a href="encodingintegers.html"><i class="fa fa-check"></i><b>14</b> Encoding categories as integers</a></li>
<li class="chapter" data-level="15" data-path="datachanges.html"><a href="datachanges.html"><i class="fa fa-check"></i><b>15</b> Forgetting that data changes over time</a></li>
<li class="chapter" data-level="16" data-path="interuservariance.html"><a href="interuservariance.html"><i class="fa fa-check"></i><b>16</b> Ignoring inter-user variance</a></li>
<li class="chapter" data-level="17" data-path="wastingunlabeled.html"><a href="wastingunlabeled.html"><i class="fa fa-check"></i><b>17</b> Wasting unlabeled data</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendixInstall.html"><a href="appendixInstall.html"><i class="fa fa-check"></i><b>A</b> Setup Your Environment</a></li>
<li class="chapter" data-level="B" data-path="appendixDatasets.html"><a href="appendixDatasets.html"><i class="fa fa-check"></i><b>B</b> Datasets</a>
<ul>
<li class="chapter" data-level="B.1" data-path="appendixDatasets.html"><a href="appendixDatasets.html#california-housing"><i class="fa fa-check"></i><b>B.1</b> CALIFORNIA-HOUSING</a></li>
<li class="chapter" data-level="B.2" data-path="appendixDatasets.html"><a href="appendixDatasets.html#diagnostic"><i class="fa fa-check"></i><b>B.2</b> DIAGNOSTIC</a></li>
<li class="chapter" data-level="B.3" data-path="appendixDatasets.html"><a href="appendixDatasets.html#digits"><i class="fa fa-check"></i><b>B.3</b> DIGITS</a></li>
<li class="chapter" data-level="B.4" data-path="appendixDatasets.html"><a href="appendixDatasets.html#income"><i class="fa fa-check"></i><b>B.4</b> INCOME</a></li>
<li class="chapter" data-level="B.5" data-path="appendixDatasets.html"><a href="appendixDatasets.html#iris"><i class="fa fa-check"></i><b>B.5</b> IRIS</a></li>
<li class="chapter" data-level="B.6" data-path="appendixDatasets.html"><a href="appendixDatasets.html#wine"><i class="fa fa-check"></i><b>B.6</b> WINE</a></li>
<li class="chapter" data-level="B.7" data-path="appendixDatasets.html"><a href="appendixDatasets.html#wisdm"><i class="fa fa-check"></i><b>B.7</b> WISDM</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="citing-this-book.html"><a href="citing-this-book.html"><i class="fa fa-check"></i>Citing this Book</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MOST COMMON MISTAKES IN MACHINE LEARNING AND HOW TO AVOID THEM</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="interuservariance" class="section level1 hasAnchor" number="16">
<h1><span class="header-section-number">Mistake 16:</span> Ignoring inter-user variance<a href="interuservariance.html#interuservariance" class="anchor-section" aria-label="Anchor link to header"></a></h1>

<div class="rmdmistake">
Ignoring inter-user variance can lead to overestimated performance metrics.
</div>
<p></br></p>
<p>There are systems that rely on individual user behaviors. For example, hand gesture recognition, activity recognition, and speech recognition systems, to name a few. These systems are called multi-user systems <span class="citation">(<a href="#ref-GarciaCejaBook">Garcia-Ceja 2021</a>)</span>. Take for example, a hand gesture classification problem based on wrist-movement data (taken from an accelerometer embedded in a smartwatch). Each person has their own way of performing the gestures and every person will perform the gestures at different speeds, wrist-orientations, etc. Those differences in the captured signals generate variance across users. In fact, there are also differences within the same user in the way they perform the same gesture multiple times but we expect the intra-user differences (variance) to be smaller compared to the inter-user differences. This inter-user variance can have a huge impact when evaluating the performance of a model.</p>
<p>Typically, the performance of a classifier is evaluated using <span class="math inline">\(k\)</span>-fold cross validation or hold-out validation. In a multi-user scenario, this will result in data from the same users being present in both, the train and test sets at the same time. This means that the trained model will already have some information for any particular user in the test set. This will allow the model to make accurate predictions for the data in the test set. However, if a completely new user wants to use the system the performance is likely to degrade since the train set did not include any information about the new user. That is, if the system is to be used by new users without going into a calibration (re-training) phase, the estimated performance metrics are likely to be overestimated. A model that is trained with data from multiple users using validation schemes like <span class="math inline">\(k\)</span>-fold cross validation is called a <em>mixed model</em>. This is because the data from multiple users is mixed as if there were only a single user.</p>
<p>In order to have a better performance estimate when the system is deployed and tested by new unknown users you can build <em>user-independent models</em> (one for each user). A user-independent model is built by taking a user of interest <span class="math inline">\(u\)</span> and excluding all their data from the training set. Then, only use the data from user <span class="math inline">\(u\)</span> as the test set. When repeating this process for every user in the database, it is called <em>leave-one-user-out validation</em>. Figure <a href="interuservariance.html#fig:louo">16.1</a> depicts this process.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:louo"></span>
<img src="images/louo.png" alt="Procedure of the leave-one-user-out validation scheme. At each iteration, the data from a particular user is exclusively included in the test set and the rest is added to the train set. Each fish represents all of its instances (not necessarily only one data point)." width="50%" />
<p class="caption">
Figure 16.1: Procedure of the leave-one-user-out validation scheme. At each iteration, the data from a particular user is exclusively included in the test set and the rest is added to the train set. Each fish represents all of its instances (not necessarily only one data point).
</p>
</div>
<p>This validation scheme will provide more accurate estimates of your model when deployed in real life. This does not mean that a user-independent model is better than a mixed model. The evaluation scheme you use will depend on your use case. A mixed model is completely fine if it is guaranteed that data from the final user will be included in the training phase. For example, asking the user to go through a calibration phase.</p>
<p>The following example uses the <em>WISDM</em> dataset for activity recognition. The dataset includes data from <span class="math inline">\(36\)</span> users. The next code snippet uses a mix-model approach by performing <span class="math inline">\(10\)</span>-fold cross validation. The <em>user</em> column which identifies every user with an id, is removed before splitting the data.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode numberSource python numberLines"><code class="sourceCode python"><span id="cb59-1"><a href="interuservariance.html#cb59-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> StratifiedKFold</span>
<span id="cb59-2"><a href="interuservariance.html#cb59-2"></a></span>
<span id="cb59-3"><a href="interuservariance.html#cb59-3"></a>X <span class="op">=</span> df.drop(columns<span class="op">=</span>[<span class="st">&#39;class&#39;</span>,<span class="st">&#39;user&#39;</span>]).values</span>
<span id="cb59-4"><a href="interuservariance.html#cb59-4"></a>y <span class="op">=</span> df[<span class="st">&quot;class&quot;</span>].values</span>
<span id="cb59-5"><a href="interuservariance.html#cb59-5"></a>kf <span class="op">=</span> StratifiedKFold(n_splits <span class="op">=</span> <span class="dv">10</span>)</span>
<span id="cb59-6"><a href="interuservariance.html#cb59-6"></a>accuracies <span class="op">=</span> []</span>
<span id="cb59-7"><a href="interuservariance.html#cb59-7"></a></span>
<span id="cb59-8"><a href="interuservariance.html#cb59-8"></a><span class="cf">for</span> i, (train_indx, test_indx) <span class="kw">in</span> <span class="bu">enumerate</span>(kf.split(X, y)):</span>
<span id="cb59-9"><a href="interuservariance.html#cb59-9"></a>    X_train <span class="op">=</span> X[train_indx]</span>
<span id="cb59-10"><a href="interuservariance.html#cb59-10"></a>    y_train <span class="op">=</span> y[train_indx]</span>
<span id="cb59-11"><a href="interuservariance.html#cb59-11"></a>    X_test <span class="op">=</span> X[test_indx]</span>
<span id="cb59-12"><a href="interuservariance.html#cb59-12"></a>    y_test <span class="op">=</span> y[test_indx]</span>
<span id="cb59-13"><a href="interuservariance.html#cb59-13"></a>    rf <span class="op">=</span> RandomForestClassifier(random_state <span class="op">=</span> <span class="dv">123</span>)</span>
<span id="cb59-14"><a href="interuservariance.html#cb59-14"></a>    rf.fit(X_train, y_train)</span>
<span id="cb59-15"><a href="interuservariance.html#cb59-15"></a>    predictions <span class="op">=</span> rf.predict(X_test)</span>
<span id="cb59-16"><a href="interuservariance.html#cb59-16"></a>    accuracies.append(accuracy_score(y_test, predictions))</span>
<span id="cb59-17"><a href="interuservariance.html#cb59-17"></a></span>
<span id="cb59-18"><a href="interuservariance.html#cb59-18"></a><span class="bu">print</span>(np.mean(accuracies))</span></code></pre></div>
<div class="sourceCode" id="cb60"><pre class="sourceCode python python-output"><code class="sourceCode python"><span id="cb60-1"><a href="interuservariance.html#cb60-1" tabindex="-1"></a><span class="co">#&gt;&gt; 0.7779597028872323</span></span></code></pre></div>
<p>The following code performs a leave-one-user-out evaluation. That is, it trains user-independent models. The <code>LeaveOneGroupOut</code> validator splits the data such that all instances in the training set are part of all groups except one. In this case, the group corresponds to the user id. That is, each user belongs to their own group.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode numberSource python numberLines"><code class="sourceCode python"><span id="cb61-1"><a href="interuservariance.html#cb61-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> LeaveOneGroupOut</span>
<span id="cb61-2"><a href="interuservariance.html#cb61-2"></a></span>
<span id="cb61-3"><a href="interuservariance.html#cb61-3"></a>users <span class="op">=</span> df[<span class="st">&quot;user&quot;</span>].values</span>
<span id="cb61-4"><a href="interuservariance.html#cb61-4"></a>X <span class="op">=</span> df.drop(columns<span class="op">=</span>[<span class="st">&#39;class&#39;</span>,<span class="st">&#39;user&#39;</span>]).values</span>
<span id="cb61-5"><a href="interuservariance.html#cb61-5"></a>y <span class="op">=</span> df[<span class="st">&quot;class&quot;</span>].values</span>
<span id="cb61-6"><a href="interuservariance.html#cb61-6"></a>valscheme <span class="op">=</span> LeaveOneGroupOut()</span>
<span id="cb61-7"><a href="interuservariance.html#cb61-7"></a>accuracies <span class="op">=</span> []</span>
<span id="cb61-8"><a href="interuservariance.html#cb61-8"></a></span>
<span id="cb61-9"><a href="interuservariance.html#cb61-9"></a><span class="cf">for</span> train_indx, test_indx <span class="kw">in</span> valscheme.split(X, y, groups <span class="op">=</span> users):</span>
<span id="cb61-10"><a href="interuservariance.html#cb61-10"></a>    X_train <span class="op">=</span> X[train_indx]</span>
<span id="cb61-11"><a href="interuservariance.html#cb61-11"></a>    y_train <span class="op">=</span> y[train_indx]</span>
<span id="cb61-12"><a href="interuservariance.html#cb61-12"></a>    X_test <span class="op">=</span> X[test_indx]</span>
<span id="cb61-13"><a href="interuservariance.html#cb61-13"></a>    y_test <span class="op">=</span> y[test_indx]</span>
<span id="cb61-14"><a href="interuservariance.html#cb61-14"></a>    rf <span class="op">=</span> RandomForestClassifier(random_state <span class="op">=</span> <span class="dv">123</span>)</span>
<span id="cb61-15"><a href="interuservariance.html#cb61-15"></a>    rf.fit(X_train, y_train)</span>
<span id="cb61-16"><a href="interuservariance.html#cb61-16"></a>    predictions <span class="op">=</span> rf.predict(X_test)</span>
<span id="cb61-17"><a href="interuservariance.html#cb61-17"></a>    accuracies.append(accuracy_score(y_test, predictions))</span>
<span id="cb61-18"><a href="interuservariance.html#cb61-18"></a></span>
<span id="cb61-19"><a href="interuservariance.html#cb61-19"></a><span class="bu">print</span>(np.mean(accuracies))</span></code></pre></div>
<div class="sourceCode" id="cb62"><pre class="sourceCode python python-output"><code class="sourceCode python"><span id="cb62-1"><a href="interuservariance.html#cb62-1" tabindex="-1"></a><span class="co">#&gt;&gt; 0.733555027660476</span></span></code></pre></div>
<p>Here, you can see that the accuracy significantly dropped with the user-independent models, thus, providing a better estimate on the expected performance with unknown users.</p>
</br>

<div class="rmdsolution">
Using different validation schemes (mixed, user-independent models, etc.) provides more robust performance metrics in multi-user scenarios.
</div>

</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-GarciaCejaBook" class="csl-entry">
Garcia-Ceja, Enrique. 2021. <em>Behavior Analysis with Machine Learning Using <span>R</span></em>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="datachanges.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="wastingunlabeled.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
